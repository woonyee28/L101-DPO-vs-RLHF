model_deployments:
  - name: huggingface/pythia-31m-dpo-100-0
    model_name: woon/pythia-31m-dpo-100-0
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-31m-DPO/checkpoint-450

  - name: huggingface/pythia-31m-dpo-80-20
    model_name: woon/pythia-31m-dpo-80-20
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-31m-DPO-80-20/checkpoint-970

  - name: huggingface/pythia-31m-dpo-50-50
    model_name: woon/pythia-31m-dpo-50-50
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-31m-DPO-50-50/checkpoint-30

  - name: huggingface/pythia-31m-ppo-100-0
    model_name: woon/pythia-31m-ppo-100-0
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-31m-PPO/checkpoint-150

  - name: huggingface/pythia-31m-ppo-80-20
    model_name: woon/pythia-31m-ppo-80-20
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-31m-PPO-80-20/checkpoint-10

  - name: huggingface/pythia-31m-ppo-50-50
    model_name: woon/pythia-31m-ppo-50-50
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-31m-PPO-50-50/checkpoint-250

  - name: huggingface/pythia-70m-dpo-100-0
    model_name: woon/pythia-70m-dpo-100-0
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-70m-deduped-DPO/checkpoint-260

  - name: huggingface/pythia-70m-dpo-80-20
    model_name: woon/pythia-70m-dpo-80-20
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-70m-deduped-DPO-80-20/checkpoint-720

  - name: huggingface/pythia-70m-dpo-50-50
    model_name: woon/pythia-70m-dpo-50-50
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-70m-deduped-DPO-50-50/checkpoint-160

  - name: huggingface/pythia-70m-ppo-100-0
    model_name: woon/pythia-70m-ppo-100-0
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-70m-deduped-PPO/checkpoint-10

  - name: huggingface/pythia-70m-ppo-80-20
    model_name: woon/pythia-70m-ppo-80-20
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-70m-deduped-PPO-80-20/checkpoint-190

  - name: huggingface/pythia-70m-ppo-50-50
    model_name: woon/pythia-70m-ppo-50-50
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-70m-deduped-PPO-50-50/checkpoint-10

  - name: huggingface/pythia-160m-dpo-100-0
    model_name: woon/pythia-160m-dpo-100-0
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-160m-deduped-DPO/checkpoint-260

  - name: huggingface/pythia-160m-dpo-80-20
    model_name: woon/pythia-160m-dpo-80-20
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-160m-deduped-DPO-80-20/checkpoint-880

  - name: huggingface/pythia-160m-dpo-50-50
    model_name: woon/pythia-160m-dpo-50-50
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-160m-deduped-DPO-50-50/checkpoint-20


  - name: huggingface/pythia-160m-ppo-100-0
    model_name: woon/pythia-160m-ppo-100-0
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-160m-deduped-PPO/checkpoint-220

  - name: huggingface/pythia-160m-ppo-80-20
    model_name: woon/pythia-160m-ppo-80-20
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-160m-deduped-PPO-80-20/checkpoint-20

  - name: huggingface/pythia-160m-ppo-50-50
    model_name: woon/pythia-160m-ppo-50-50
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-160m-deduped-PPO-50-50/checkpoint-200
