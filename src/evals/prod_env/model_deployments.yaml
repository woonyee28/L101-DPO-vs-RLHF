model_deployments:
  - name: huggingface/pythia-31m-dpo-100-0
    model_name: woon/pythia-31m-dpo-100-0
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-31m-deduped-DPO/checkpoint-520

  - name: huggingface/pythia-31m-dpo-80-20
    model_name: woon/pythia-31m-dpo-80-20
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-31m-deduped-DPO-80-20/checkpoint-860

  - name: huggingface/pythia-31m-dpo-50-50
    model_name: woon/pythia-31m-dpo-50-50
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-31m-deduped-DPO-50-50/checkpoint-160

  - name: huggingface/pythia-31m-ppo-100-0
    model_name: woon/pythia-31m-ppo-100-0
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-31m-deduped-PPO/checkpoint-100

  - name: huggingface/pythia-31m-ppo-80-20
    model_name: woon/pythia-31m-ppo-80-20
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-31m-deduped-PPO-80-20/checkpoint-240

  - name: huggingface/pythia-31m-ppo-50-50
    model_name: woon/pythia-31m-ppo-50-50
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-31m-deduped-PPO-50-50/checkpoint-20

  - name: huggingface/pythia-70m-dpo-100-0
    model_name: woon/pythia-70m-dpo-100-0
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-70m-deduped-DPO/checkpoint-420

  - name: huggingface/pythia-70m-dpo-80-20
    model_name: woon/pythia-70m-dpo-80-20
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-70m-deduped-DPO-80-20/checkpoint-740

  - name: huggingface/pythia-70m-dpo-50-50
    model_name: woon/pythia-70m-dpo-50-50
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-70m-deduped-DPO-50-50/checkpoint-140

  - name: huggingface/pythia-70m-ppo-100-0
    model_name: woon/pythia-70m-ppo-100-0
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-70m-deduped-PPO/checkpoint-240

  - name: huggingface/pythia-70m-ppo-80-20
    model_name: woon/pythia-70m-ppo-80-20
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-70m-deduped-PPO-80-20/checkpoint-200

  - name: huggingface/pythia-70m-ppo-50-50
    model_name: woon/pythia-70m-ppo-50-50
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-70m-deduped-PPO-50-50/checkpoint-160

  - name: huggingface/pythia-160m-dpo-100-0
    model_name: woon/pythia-160m-dpo-100-0
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-160m-deduped-DPO/checkpoint-140

  - name: huggingface/pythia-160m-dpo-80-20
    model_name: woon/pythia-160m-dpo-80-20
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-160m-deduped-DPO-80-20/checkpoint-680

  - name: huggingface/pythia-160m-dpo-50-50
    model_name: woon/pythia-160m-dpo-50-50
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-160m-deduped-DPO-50-50/checkpoint-100


  - name: huggingface/pythia-160m-ppo-100-0
    model_name: woon/pythia-160m-ppo-100-0
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-160m-deduped-PPO/checkpoint-240

  - name: huggingface/pythia-160m-ppo-80-20
    model_name: woon/pythia-160m-ppo-80-20
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-160m-deduped-PPO-80-20/checkpoint-220

  - name: huggingface/pythia-160m-ppo-50-50
    model_name: woon/pythia-160m-ppo-50-50
    tokenizer_name: EleutherAI/gpt-neox-20b
    max_sequence_length: 2048
    client_spec:
      class_name: "helm.clients.huggingface_client.HuggingFaceClient"
      args:
        pretrained_model_name_or_path: /home/wyn23/l101/notebooks/pythia-160m-deduped-PPO-50-50/checkpoint-120
