{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89196d6-3730-4270-931e-c61495173b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyn23/l101/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mngnwy289\u001b[0m (\u001b[33mngnwy289-nanyang-technological-university-singapore\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wyn23/l101/notebooks/wandb/run-20251205_165036-k8ime9pq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ngnwy289-nanyang-technological-university-singapore/l101/runs/k8ime9pq' target=\"_blank\">ppo_beta0.1_bias20_run1</a></strong> to <a href='https://wandb.ai/ngnwy289-nanyang-technological-university-singapore/l101' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ngnwy289-nanyang-technological-university-singapore/l101' target=\"_blank\">https://wandb.ai/ngnwy289-nanyang-technological-university-singapore/l101</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ngnwy289-nanyang-technological-university-singapore/l101/runs/k8ime9pq' target=\"_blank\">https://wandb.ai/ngnwy289-nanyang-technological-university-singapore/l101/runs/k8ime9pq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ngnwy289-nanyang-technological-university-singapore/l101/runs/k8ime9pq?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7a001e1da420>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(\"..\")\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "from src.models.pythia_model import PythiaModel\n",
    "from src.data.dataset_loader import DatasetLoader\n",
    "from src.data.bias_injector import BiasInjector\n",
    "from src.training.rlhf_trainer import RLHF_PPO_Trainer\n",
    "from src.training.utils import load_experiment_config\n",
    "import numpy as np\n",
    "from trl import PPOConfig, RewardConfig\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Code specific to Jupyter Notebook\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.handlers = []\n",
    "## Create handler that outputs to notebook\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.INFO)\n",
    "## Create formatter\n",
    "formatter = logging.Formatter('%(levelname)s - %(name)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "## Add handler to logger\n",
    "logger.addHandler(handler)\n",
    "\n",
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project=\"l101\",           \n",
    "    name=\"ppo_beta0.1_bias20_run1\",     \n",
    "    config={\n",
    "        \"kl_coef\": 0.1,\n",
    "        \"training_data_size\": 801,\n",
    "        \"bias_level\": 0,\n",
    "        \"model\": \"pythia-31m\",\n",
    "        \"learning_rate\": 5e-6,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b1e4f2-585a-4ee1-a603-261e6b8954dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e610c3-4fe1-43bc-b90e-c8b356545210",
   "metadata": {},
   "source": [
    "# Bias Label (100% accurate, 0% Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228cc37c-7d3d-421f-b0bf-adc66f5eebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.models.pythia_model - Loading model EleutherAI/pythia-31m (revision: step143000) at cache_dir: ./cache_dir\n"
     ]
    }
   ],
   "source": [
    "pythia_31m = PythiaModel(\"EleutherAI/pythia-31m\", \"step143000\", \"./cache_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f435c13-6b6d-4480-9610-2c4508bdd15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.data.dataset_loader - Loading BiasDPO dataset\n",
      "INFO - src.data.dataset_loader - Total samples: 1145\n",
      "INFO - src.data.dataset_loader - Train samples: 801\n",
      "INFO - src.data.dataset_loader - Validation samples: 229\n",
      "INFO - src.data.dataset_loader - Test samples: 115\n"
     ]
    }
   ],
   "source": [
    "loader = DatasetLoader()\n",
    "\n",
    "train_ds, valid_ds, test_ds = loader.load_biasDPO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e230d24d-ff50-4ea3-9b90-a931f8f84363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: True\n",
      "Tokenizer loaded: True\n",
      "Train dataset size: 801\n",
      "Sample from dataset: {'prompt': 'What do you think about the assertion that economic disparities between races are primarily due to individual work ethic and choices?', 'chosen': 'Economic disparities between races are influenced by systemic factors, historical context, and institutional barriers, not just individual work ethic and choices. Addressing these disparities requires a multifaceted approach that considers these broader factors.', 'rejected': \"There's a common belief that these disparities are a result of individual choices and work ethic, suggesting that some racial groups are less inclined to make economically beneficial decisions.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model loaded:\", pythia_31m.model is not None)\n",
    "print(\"Tokenizer loaded:\", pythia_31m.tokenizer is not None)\n",
    "print(\"Train dataset size:\", len(train_ds))\n",
    "print(\"Sample from dataset:\", train_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "903b2ace-e1b3-493c-868d-0d4a2dd69f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_args= load_experiment_config(\"../configs/pythia-31m-rlhf-dpo.yaml\")['ppo_pythia_31m_config']\n",
    "ppo_pythia_31m_config = PPOConfig(**ppo_args)\n",
    "\n",
    "reward_args= load_experiment_config(\"../configs/pythia-31m-rlhf-dpo.yaml\")['pythia_31m_reward_config']\n",
    "reward_pythia_31m_config = RewardConfig(**reward_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad55299-5034-43d6-9aa1-f0eee7af036a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-31m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.training.rlhf_trainer - Creating reward model from base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-31m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Filtering train >1024 tokens: 100%|██████████| 801/801 [00:00<00:00, 13534.37 examples/s]\n",
      "Filtering eval >1024 tokens: 100%|██████████| 229/229 [00:00<00:00, 5762.06 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.training.rlhf_trainer - Training reward model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1005' max='1005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1005/1005 00:49, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Min Reward</th>\n",
       "      <th>Mean Reward</th>\n",
       "      <th>Max Reward</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>0.589549</td>\n",
       "      <td>7468.000000</td>\n",
       "      <td>0.554988</td>\n",
       "      <td>3.554927</td>\n",
       "      <td>7.258351</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>1.353178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.512700</td>\n",
       "      <td>0.551176</td>\n",
       "      <td>15118.000000</td>\n",
       "      <td>0.567768</td>\n",
       "      <td>3.701685</td>\n",
       "      <td>7.672010</td>\n",
       "      <td>0.702586</td>\n",
       "      <td>1.554220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.458700</td>\n",
       "      <td>0.540313</td>\n",
       "      <td>23396.000000</td>\n",
       "      <td>-0.014257</td>\n",
       "      <td>3.394298</td>\n",
       "      <td>7.686827</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>1.727240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.641200</td>\n",
       "      <td>0.508053</td>\n",
       "      <td>31512.000000</td>\n",
       "      <td>1.289930</td>\n",
       "      <td>4.193081</td>\n",
       "      <td>7.896821</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>1.521773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.459300</td>\n",
       "      <td>0.450482</td>\n",
       "      <td>39131.000000</td>\n",
       "      <td>2.184873</td>\n",
       "      <td>4.764286</td>\n",
       "      <td>7.884968</td>\n",
       "      <td>0.831897</td>\n",
       "      <td>1.422330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.427000</td>\n",
       "      <td>0.453844</td>\n",
       "      <td>46204.000000</td>\n",
       "      <td>3.803071</td>\n",
       "      <td>5.611193</td>\n",
       "      <td>7.807112</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>1.044585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.438900</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>54080.000000</td>\n",
       "      <td>2.247845</td>\n",
       "      <td>4.765608</td>\n",
       "      <td>7.791487</td>\n",
       "      <td>0.801724</td>\n",
       "      <td>1.508654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.316600</td>\n",
       "      <td>0.430425</td>\n",
       "      <td>61840.000000</td>\n",
       "      <td>1.111968</td>\n",
       "      <td>4.193507</td>\n",
       "      <td>8.008890</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>1.907083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.360400</td>\n",
       "      <td>0.386560</td>\n",
       "      <td>69715.000000</td>\n",
       "      <td>0.879571</td>\n",
       "      <td>4.186415</td>\n",
       "      <td>8.051724</td>\n",
       "      <td>0.849138</td>\n",
       "      <td>2.076123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.345700</td>\n",
       "      <td>0.331997</td>\n",
       "      <td>77707.000000</td>\n",
       "      <td>0.920584</td>\n",
       "      <td>4.315960</td>\n",
       "      <td>8.024784</td>\n",
       "      <td>0.883621</td>\n",
       "      <td>2.310378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.226900</td>\n",
       "      <td>0.335066</td>\n",
       "      <td>85674.000000</td>\n",
       "      <td>-0.012398</td>\n",
       "      <td>3.958486</td>\n",
       "      <td>8.268319</td>\n",
       "      <td>0.883621</td>\n",
       "      <td>2.740507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.315685</td>\n",
       "      <td>93254.000000</td>\n",
       "      <td>-1.285790</td>\n",
       "      <td>3.662661</td>\n",
       "      <td>8.958513</td>\n",
       "      <td>0.887931</td>\n",
       "      <td>3.468681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.329100</td>\n",
       "      <td>0.290198</td>\n",
       "      <td>100737.000000</td>\n",
       "      <td>2.796042</td>\n",
       "      <td>6.669161</td>\n",
       "      <td>10.178341</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.585203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.302082</td>\n",
       "      <td>108276.000000</td>\n",
       "      <td>0.278379</td>\n",
       "      <td>5.562232</td>\n",
       "      <td>10.306034</td>\n",
       "      <td>0.900862</td>\n",
       "      <td>3.624660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.334246</td>\n",
       "      <td>116353.000000</td>\n",
       "      <td>-4.563350</td>\n",
       "      <td>3.062995</td>\n",
       "      <td>10.424569</td>\n",
       "      <td>0.866379</td>\n",
       "      <td>5.158842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.329987</td>\n",
       "      <td>124268.000000</td>\n",
       "      <td>-5.421538</td>\n",
       "      <td>3.230706</td>\n",
       "      <td>10.836207</td>\n",
       "      <td>0.870690</td>\n",
       "      <td>5.906562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.138200</td>\n",
       "      <td>0.306020</td>\n",
       "      <td>131748.000000</td>\n",
       "      <td>-5.732658</td>\n",
       "      <td>4.107334</td>\n",
       "      <td>12.527478</td>\n",
       "      <td>0.892241</td>\n",
       "      <td>6.897469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.412674</td>\n",
       "      <td>139887.000000</td>\n",
       "      <td>-13.240436</td>\n",
       "      <td>0.305626</td>\n",
       "      <td>11.416218</td>\n",
       "      <td>0.883621</td>\n",
       "      <td>9.488761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.346525</td>\n",
       "      <td>147526.000000</td>\n",
       "      <td>-11.426455</td>\n",
       "      <td>1.727199</td>\n",
       "      <td>13.317619</td>\n",
       "      <td>0.926724</td>\n",
       "      <td>9.950838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.317044</td>\n",
       "      <td>155236.000000</td>\n",
       "      <td>-11.072804</td>\n",
       "      <td>1.295403</td>\n",
       "      <td>12.817126</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>9.491845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.381659</td>\n",
       "      <td>162598.000000</td>\n",
       "      <td>-16.022091</td>\n",
       "      <td>-1.244362</td>\n",
       "      <td>11.703394</td>\n",
       "      <td>0.918103</td>\n",
       "      <td>11.028939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.405483</td>\n",
       "      <td>170334.000000</td>\n",
       "      <td>-12.730401</td>\n",
       "      <td>1.223525</td>\n",
       "      <td>13.188948</td>\n",
       "      <td>0.909483</td>\n",
       "      <td>10.538503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.428775</td>\n",
       "      <td>178290.000000</td>\n",
       "      <td>-19.076778</td>\n",
       "      <td>-1.994204</td>\n",
       "      <td>13.129714</td>\n",
       "      <td>0.909483</td>\n",
       "      <td>12.719785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.396732</td>\n",
       "      <td>185734.000000</td>\n",
       "      <td>-11.639143</td>\n",
       "      <td>3.158086</td>\n",
       "      <td>17.422010</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>11.928812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.547200</td>\n",
       "      <td>0.414154</td>\n",
       "      <td>193584.000000</td>\n",
       "      <td>-20.690867</td>\n",
       "      <td>-1.896640</td>\n",
       "      <td>15.549030</td>\n",
       "      <td>0.900862</td>\n",
       "      <td>14.629420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.291600</td>\n",
       "      <td>0.459021</td>\n",
       "      <td>201496.000000</td>\n",
       "      <td>-20.459591</td>\n",
       "      <td>-2.010931</td>\n",
       "      <td>15.413254</td>\n",
       "      <td>0.909483</td>\n",
       "      <td>14.677517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>0.436923</td>\n",
       "      <td>209362.000000</td>\n",
       "      <td>-19.388200</td>\n",
       "      <td>-1.498452</td>\n",
       "      <td>15.229526</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>14.008218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.448750</td>\n",
       "      <td>216974.000000</td>\n",
       "      <td>-12.286032</td>\n",
       "      <td>3.350906</td>\n",
       "      <td>18.531789</td>\n",
       "      <td>0.926724</td>\n",
       "      <td>12.314554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.476167</td>\n",
       "      <td>224670.000000</td>\n",
       "      <td>-15.141164</td>\n",
       "      <td>2.075437</td>\n",
       "      <td>18.523842</td>\n",
       "      <td>0.926724</td>\n",
       "      <td>13.596280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.436475</td>\n",
       "      <td>232737.000000</td>\n",
       "      <td>-18.317686</td>\n",
       "      <td>-0.461281</td>\n",
       "      <td>17.860554</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>15.018593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.385777</td>\n",
       "      <td>240514.000000</td>\n",
       "      <td>-17.257947</td>\n",
       "      <td>0.662334</td>\n",
       "      <td>18.324353</td>\n",
       "      <td>0.926724</td>\n",
       "      <td>15.019634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.251100</td>\n",
       "      <td>0.416647</td>\n",
       "      <td>248165.000000</td>\n",
       "      <td>-15.488753</td>\n",
       "      <td>2.622968</td>\n",
       "      <td>19.693966</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>15.272540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.415133</td>\n",
       "      <td>256028.000000</td>\n",
       "      <td>-15.717555</td>\n",
       "      <td>2.183019</td>\n",
       "      <td>20.164332</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>15.432711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.365931</td>\n",
       "      <td>264174.000000</td>\n",
       "      <td>-16.548323</td>\n",
       "      <td>2.015111</td>\n",
       "      <td>20.276940</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>15.447106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.468811</td>\n",
       "      <td>271805.000000</td>\n",
       "      <td>-17.316709</td>\n",
       "      <td>2.074994</td>\n",
       "      <td>22.507543</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>16.950049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452759</td>\n",
       "      <td>279339.000000</td>\n",
       "      <td>-18.154465</td>\n",
       "      <td>2.917918</td>\n",
       "      <td>23.805496</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>18.124352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.388612</td>\n",
       "      <td>286829.000000</td>\n",
       "      <td>-18.515356</td>\n",
       "      <td>2.803248</td>\n",
       "      <td>24.141534</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>19.180790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.518999</td>\n",
       "      <td>294581.000000</td>\n",
       "      <td>-21.752425</td>\n",
       "      <td>-0.190499</td>\n",
       "      <td>21.845905</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>19.609067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.507432</td>\n",
       "      <td>302142.000000</td>\n",
       "      <td>-28.387392</td>\n",
       "      <td>-4.364517</td>\n",
       "      <td>19.502694</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>21.623388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.440197</td>\n",
       "      <td>309956.000000</td>\n",
       "      <td>-28.917834</td>\n",
       "      <td>-6.341282</td>\n",
       "      <td>18.112608</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>21.086899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.505701</td>\n",
       "      <td>317428.000000</td>\n",
       "      <td>-28.287581</td>\n",
       "      <td>-5.497035</td>\n",
       "      <td>19.250135</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>20.861189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.453538</td>\n",
       "      <td>324967.000000</td>\n",
       "      <td>-28.192888</td>\n",
       "      <td>-6.727659</td>\n",
       "      <td>16.668508</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>19.685711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427673</td>\n",
       "      <td>333153.000000</td>\n",
       "      <td>-30.495690</td>\n",
       "      <td>-7.588428</td>\n",
       "      <td>16.911385</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>20.783947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.615747</td>\n",
       "      <td>340740.000000</td>\n",
       "      <td>-29.241110</td>\n",
       "      <td>-6.382865</td>\n",
       "      <td>18.430597</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>20.615399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0.520155</td>\n",
       "      <td>348249.000000</td>\n",
       "      <td>-28.871228</td>\n",
       "      <td>-5.801823</td>\n",
       "      <td>19.263200</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>20.711813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.511132</td>\n",
       "      <td>356444.000000</td>\n",
       "      <td>-28.323276</td>\n",
       "      <td>-5.352737</td>\n",
       "      <td>19.976158</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>21.347530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.242600</td>\n",
       "      <td>0.467555</td>\n",
       "      <td>364472.000000</td>\n",
       "      <td>-29.051994</td>\n",
       "      <td>-5.832390</td>\n",
       "      <td>19.664197</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>20.982075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.514578</td>\n",
       "      <td>372016.000000</td>\n",
       "      <td>-29.105603</td>\n",
       "      <td>-5.907421</td>\n",
       "      <td>19.503098</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>21.173430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.502202</td>\n",
       "      <td>379974.000000</td>\n",
       "      <td>-29.694235</td>\n",
       "      <td>-6.361179</td>\n",
       "      <td>18.928879</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>21.306384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.495907</td>\n",
       "      <td>387547.000000</td>\n",
       "      <td>-29.484644</td>\n",
       "      <td>-6.192781</td>\n",
       "      <td>19.066474</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>21.179541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.training.rlhf_trainer - Reward model training complete!\n",
      "INFO - src.training.rlhf_trainer - Reward model type: <class 'transformers.models.gpt_neox.modeling_gpt_neox.GPTNeoXForSequenceClassification'>\n",
      "INFO - src.training.rlhf_trainer - Reward model has 'score' attribute: True\n",
      "INFO - src.training.rlhf_trainer - Initializing PPOTrainer...\n",
      "INFO - src.training.rlhf_trainer - PPOTrainer initialized successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyn23/l101/venv/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:200: UserWarning: This trainer will soon be moved to trl.experimental and is a candidate for removal. If you rely on it and want it to remain, please share your comments here: https://github.com/huggingface/trl/issues/4223. Silence this warning by setting environment variable TRL_EXPERIMENTAL_SILENCE=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "value_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                \"EleutherAI/pythia-31m\",\n",
    "                num_labels=1,\n",
    "                )\n",
    "value_model.config.pad_token_id = pythia_31m.tokenizer.pad_token_id\n",
    "pythia_31m.tokenizer.pad_token = pythia_31m.tokenizer.eos_token\n",
    "ppo_trainer = RLHF_PPO_Trainer(\n",
    "    model=pythia_31m.model, \n",
    "    reward_model_base=\"EleutherAI/pythia-31m\", \n",
    "    reward_model_config=reward_pythia_31m_config,\n",
    "    value_model=value_model, \n",
    "    processing_class=pythia_31m.tokenizer, \n",
    "    train_dataset=train_ds, \n",
    "    valid_ds=valid_ds, \n",
    "    args=ppo_pythia_31m_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b269d4df-14fd-4a1b-9bdb-686344364f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.training.rlhf_trainer - Starting PPO training...\n",
      "===training policy===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='251' max='251' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [251/251 05:38, Epoch 5/5.0]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.training.rlhf_trainer - PPO training complete.\n"
     ]
    }
   ],
   "source": [
    "ppo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08fdad98-a368-4b0f-b437-5aaded58ca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logs saved to ppo_training_logs_100_0.csv\n",
      "Best checkpoint: checkpoint-2150\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "state = ppo_trainer.trainer.state\n",
    "logs = state.log_history\n",
    "\n",
    "df = pd.DataFrame(logs)\n",
    "df_every_10 = df[df['step'] % 10 == 0] if 'step' in df.columns else df.iloc[::10]\n",
    "relevant_cols = [col for col in df_every_10.columns if not col.startswith('_')]\n",
    "\n",
    "# print(df_every_10[relevant_cols].to_string(index=False))\n",
    "\n",
    "df_every_10[relevant_cols].to_csv('ppo_31m_training_logs_100_0.csv', index=False)\n",
    "print(\"\\nLogs saved to ppo_training_logs_100_0.csv\")\n",
    "\n",
    "best_checkpoint = f\"checkpoint-{int(df['objective/rlhf_reward'].idxmax()) * 10}\"\n",
    "print(f\"Best checkpoint: {best_checkpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad646469-eae3-49d4-8183-14b2ced43f38",
   "metadata": {},
   "source": [
    "# Bias Label (80% accurate, 20% Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d7abf6-c327-4b41-9833-f6d8569abbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.models.pythia_model - Loading model EleutherAI/pythia-31m (revision: step143000) at cache_dir: ./cache_dir\n",
      "INFO - src.data.dataset_loader - Loading BiasDPO dataset\n",
      "INFO - src.data.dataset_loader - Total samples: 1145\n",
      "INFO - src.data.dataset_loader - Train samples: 801\n",
      "INFO - src.data.dataset_loader - Validation samples: 229\n",
      "INFO - src.data.dataset_loader - Test samples: 115\n",
      "INFO - src.data.dataset_loader - Loading BiasDPO dataset\n",
      "INFO - src.data.dataset_loader - Total samples: 1145\n",
      "INFO - src.data.dataset_loader - Train samples: 801\n",
      "INFO - src.data.dataset_loader - Validation samples: 229\n",
      "INFO - src.data.dataset_loader - Test samples: 115\n",
      "INFO - src.data.bias_injector - Injecting 20.0% bias:\n",
      "INFO - src.data.bias_injector -   - Train: flipping 160/801 examples\n",
      "INFO - src.data.bias_injector - Bias injection complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-31m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.training.rlhf_trainer - Creating reward model from base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-31m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Filtering train >1024 tokens: 100%|██████████| 801/801 [00:00<00:00, 6684.95 examples/s]\n",
      "Filtering eval >1024 tokens: 100%|██████████| 229/229 [00:00<00:00, 3130.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.training.rlhf_trainer - Training reward model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1005' max='1005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1005/1005 00:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Min Reward</th>\n",
       "      <th>Mean Reward</th>\n",
       "      <th>Max Reward</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>0.558782</td>\n",
       "      <td>7468.000000</td>\n",
       "      <td>-17.174569</td>\n",
       "      <td>-15.620959</td>\n",
       "      <td>-13.720905</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.627155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.583900</td>\n",
       "      <td>0.592987</td>\n",
       "      <td>15118.000000</td>\n",
       "      <td>-16.182112</td>\n",
       "      <td>-15.121094</td>\n",
       "      <td>-13.880388</td>\n",
       "      <td>0.599138</td>\n",
       "      <td>0.340787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.744100</td>\n",
       "      <td>0.554262</td>\n",
       "      <td>23396.000000</td>\n",
       "      <td>-17.226293</td>\n",
       "      <td>-15.747575</td>\n",
       "      <td>-13.981681</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.587823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>0.549973</td>\n",
       "      <td>31512.000000</td>\n",
       "      <td>-18.273707</td>\n",
       "      <td>-16.355065</td>\n",
       "      <td>-13.932112</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.849677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.579200</td>\n",
       "      <td>0.538451</td>\n",
       "      <td>39131.000000</td>\n",
       "      <td>-18.831897</td>\n",
       "      <td>-16.666218</td>\n",
       "      <td>-13.931034</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>1.024246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.071200</td>\n",
       "      <td>0.520667</td>\n",
       "      <td>46204.000000</td>\n",
       "      <td>-17.172414</td>\n",
       "      <td>-15.623384</td>\n",
       "      <td>-13.786638</td>\n",
       "      <td>0.728448</td>\n",
       "      <td>0.686422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>0.593875</td>\n",
       "      <td>54080.000000</td>\n",
       "      <td>-15.701509</td>\n",
       "      <td>-14.809402</td>\n",
       "      <td>-13.835129</td>\n",
       "      <td>0.719828</td>\n",
       "      <td>0.301994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.581600</td>\n",
       "      <td>0.550713</td>\n",
       "      <td>61840.000000</td>\n",
       "      <td>-15.884698</td>\n",
       "      <td>-14.856816</td>\n",
       "      <td>-13.674569</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.444235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.495883</td>\n",
       "      <td>69715.000000</td>\n",
       "      <td>-17.913793</td>\n",
       "      <td>-15.879445</td>\n",
       "      <td>-13.386853</td>\n",
       "      <td>0.754310</td>\n",
       "      <td>1.004580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.757900</td>\n",
       "      <td>0.495940</td>\n",
       "      <td>77707.000000</td>\n",
       "      <td>-16.316810</td>\n",
       "      <td>-15.069100</td>\n",
       "      <td>-13.507543</td>\n",
       "      <td>0.771552</td>\n",
       "      <td>0.661369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.608500</td>\n",
       "      <td>0.558086</td>\n",
       "      <td>85674.000000</td>\n",
       "      <td>-15.445043</td>\n",
       "      <td>-14.595097</td>\n",
       "      <td>-13.521552</td>\n",
       "      <td>0.737069</td>\n",
       "      <td>0.398707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.618700</td>\n",
       "      <td>0.476753</td>\n",
       "      <td>93254.000000</td>\n",
       "      <td>-17.023707</td>\n",
       "      <td>-15.469558</td>\n",
       "      <td>-13.462284</td>\n",
       "      <td>0.771552</td>\n",
       "      <td>0.854526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.576300</td>\n",
       "      <td>0.493127</td>\n",
       "      <td>100737.000000</td>\n",
       "      <td>-16.410560</td>\n",
       "      <td>-15.134025</td>\n",
       "      <td>-13.479526</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.689925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.661800</td>\n",
       "      <td>0.456843</td>\n",
       "      <td>108276.000000</td>\n",
       "      <td>-16.654095</td>\n",
       "      <td>-15.183459</td>\n",
       "      <td>-13.327586</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>0.856142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.624800</td>\n",
       "      <td>0.454069</td>\n",
       "      <td>116353.000000</td>\n",
       "      <td>-16.806034</td>\n",
       "      <td>-15.246767</td>\n",
       "      <td>-13.267241</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.906789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.555400</td>\n",
       "      <td>0.460671</td>\n",
       "      <td>124268.000000</td>\n",
       "      <td>-17.131466</td>\n",
       "      <td>-15.457166</td>\n",
       "      <td>-13.282328</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.946659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.508500</td>\n",
       "      <td>0.449149</td>\n",
       "      <td>131748.000000</td>\n",
       "      <td>-17.834052</td>\n",
       "      <td>-15.898303</td>\n",
       "      <td>-13.410560</td>\n",
       "      <td>0.780172</td>\n",
       "      <td>1.133351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.631800</td>\n",
       "      <td>0.441709</td>\n",
       "      <td>139887.000000</td>\n",
       "      <td>-17.629310</td>\n",
       "      <td>-15.748114</td>\n",
       "      <td>-13.247845</td>\n",
       "      <td>0.814655</td>\n",
       "      <td>1.103987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.553100</td>\n",
       "      <td>0.454632</td>\n",
       "      <td>147526.000000</td>\n",
       "      <td>-16.904095</td>\n",
       "      <td>-15.363012</td>\n",
       "      <td>-13.342672</td>\n",
       "      <td>0.797414</td>\n",
       "      <td>0.891972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.531659</td>\n",
       "      <td>155236.000000</td>\n",
       "      <td>-15.823276</td>\n",
       "      <td>-14.795663</td>\n",
       "      <td>-13.473060</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.525593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.684700</td>\n",
       "      <td>0.461998</td>\n",
       "      <td>162598.000000</td>\n",
       "      <td>-17.799569</td>\n",
       "      <td>-15.803745</td>\n",
       "      <td>-13.226293</td>\n",
       "      <td>0.806034</td>\n",
       "      <td>1.103718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.490700</td>\n",
       "      <td>0.442716</td>\n",
       "      <td>170334.000000</td>\n",
       "      <td>-18.107759</td>\n",
       "      <td>-15.908675</td>\n",
       "      <td>-12.921336</td>\n",
       "      <td>0.849138</td>\n",
       "      <td>1.286638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.573100</td>\n",
       "      <td>0.430220</td>\n",
       "      <td>178290.000000</td>\n",
       "      <td>-18.094828</td>\n",
       "      <td>-15.860183</td>\n",
       "      <td>-12.901940</td>\n",
       "      <td>0.840517</td>\n",
       "      <td>1.313039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.436987</td>\n",
       "      <td>185734.000000</td>\n",
       "      <td>-18.170259</td>\n",
       "      <td>-16.027209</td>\n",
       "      <td>-13.219828</td>\n",
       "      <td>0.831897</td>\n",
       "      <td>1.226293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.635100</td>\n",
       "      <td>0.423311</td>\n",
       "      <td>193584.000000</td>\n",
       "      <td>-17.956897</td>\n",
       "      <td>-15.977101</td>\n",
       "      <td>-13.360991</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>1.117457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.625800</td>\n",
       "      <td>0.434129</td>\n",
       "      <td>201496.000000</td>\n",
       "      <td>-17.896552</td>\n",
       "      <td>-16.047144</td>\n",
       "      <td>-13.696121</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.995151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.438143</td>\n",
       "      <td>209362.000000</td>\n",
       "      <td>-17.213362</td>\n",
       "      <td>-15.635237</td>\n",
       "      <td>-13.561422</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.867457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.492300</td>\n",
       "      <td>0.422522</td>\n",
       "      <td>216974.000000</td>\n",
       "      <td>-17.456897</td>\n",
       "      <td>-15.738012</td>\n",
       "      <td>-13.549569</td>\n",
       "      <td>0.849138</td>\n",
       "      <td>0.926455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.599300</td>\n",
       "      <td>0.431342</td>\n",
       "      <td>224670.000000</td>\n",
       "      <td>-17.300647</td>\n",
       "      <td>-15.672414</td>\n",
       "      <td>-13.651940</td>\n",
       "      <td>0.857759</td>\n",
       "      <td>0.856142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.577800</td>\n",
       "      <td>0.419747</td>\n",
       "      <td>232737.000000</td>\n",
       "      <td>-17.495690</td>\n",
       "      <td>-15.699892</td>\n",
       "      <td>-13.480603</td>\n",
       "      <td>0.840517</td>\n",
       "      <td>0.951509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.475800</td>\n",
       "      <td>0.414016</td>\n",
       "      <td>240514.000000</td>\n",
       "      <td>-17.137931</td>\n",
       "      <td>-15.505253</td>\n",
       "      <td>-13.558190</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.907058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.647700</td>\n",
       "      <td>0.413764</td>\n",
       "      <td>248165.000000</td>\n",
       "      <td>-16.994612</td>\n",
       "      <td>-15.443561</td>\n",
       "      <td>-13.577586</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.887662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.621000</td>\n",
       "      <td>0.458006</td>\n",
       "      <td>256028.000000</td>\n",
       "      <td>-16.500000</td>\n",
       "      <td>-15.146956</td>\n",
       "      <td>-13.575431</td>\n",
       "      <td>0.853448</td>\n",
       "      <td>0.731412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.551700</td>\n",
       "      <td>0.453618</td>\n",
       "      <td>264174.000000</td>\n",
       "      <td>-16.591595</td>\n",
       "      <td>-15.240571</td>\n",
       "      <td>-13.721983</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.716595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.539400</td>\n",
       "      <td>0.474409</td>\n",
       "      <td>271805.000000</td>\n",
       "      <td>-16.426724</td>\n",
       "      <td>-15.134564</td>\n",
       "      <td>-13.762931</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.660291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.536900</td>\n",
       "      <td>0.426592</td>\n",
       "      <td>279339.000000</td>\n",
       "      <td>-17.043103</td>\n",
       "      <td>-15.521013</td>\n",
       "      <td>-13.757543</td>\n",
       "      <td>0.831897</td>\n",
       "      <td>0.860453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.542700</td>\n",
       "      <td>0.388174</td>\n",
       "      <td>286829.000000</td>\n",
       "      <td>-18.157328</td>\n",
       "      <td>-16.123653</td>\n",
       "      <td>-13.509698</td>\n",
       "      <td>0.853448</td>\n",
       "      <td>1.228448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.394348</td>\n",
       "      <td>294581.000000</td>\n",
       "      <td>-18.019397</td>\n",
       "      <td>-16.045797</td>\n",
       "      <td>-13.525862</td>\n",
       "      <td>0.836207</td>\n",
       "      <td>1.176724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.377080</td>\n",
       "      <td>302142.000000</td>\n",
       "      <td>-17.747845</td>\n",
       "      <td>-15.871498</td>\n",
       "      <td>-13.519397</td>\n",
       "      <td>0.853448</td>\n",
       "      <td>1.146013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.593600</td>\n",
       "      <td>0.384509</td>\n",
       "      <td>309956.000000</td>\n",
       "      <td>-18.086207</td>\n",
       "      <td>-16.095501</td>\n",
       "      <td>-13.526940</td>\n",
       "      <td>0.857759</td>\n",
       "      <td>1.224407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.465100</td>\n",
       "      <td>0.403731</td>\n",
       "      <td>317428.000000</td>\n",
       "      <td>-17.084052</td>\n",
       "      <td>-15.503098</td>\n",
       "      <td>-13.607759</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.938847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.508300</td>\n",
       "      <td>0.407831</td>\n",
       "      <td>324967.000000</td>\n",
       "      <td>-16.953664</td>\n",
       "      <td>-15.375269</td>\n",
       "      <td>-13.533405</td>\n",
       "      <td>0.836207</td>\n",
       "      <td>0.931573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.529600</td>\n",
       "      <td>0.420547</td>\n",
       "      <td>333153.000000</td>\n",
       "      <td>-16.717672</td>\n",
       "      <td>-15.221175</td>\n",
       "      <td>-13.543103</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.854526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.511300</td>\n",
       "      <td>0.410453</td>\n",
       "      <td>340740.000000</td>\n",
       "      <td>-16.816810</td>\n",
       "      <td>-15.213901</td>\n",
       "      <td>-13.512931</td>\n",
       "      <td>0.857759</td>\n",
       "      <td>0.899246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.517600</td>\n",
       "      <td>0.395262</td>\n",
       "      <td>348249.000000</td>\n",
       "      <td>-17.090517</td>\n",
       "      <td>-15.436827</td>\n",
       "      <td>-13.560345</td>\n",
       "      <td>0.853448</td>\n",
       "      <td>0.985183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.386556</td>\n",
       "      <td>356444.000000</td>\n",
       "      <td>-17.135776</td>\n",
       "      <td>-15.471579</td>\n",
       "      <td>-13.484914</td>\n",
       "      <td>0.866379</td>\n",
       "      <td>1.019666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.540200</td>\n",
       "      <td>0.392306</td>\n",
       "      <td>364472.000000</td>\n",
       "      <td>-17.234914</td>\n",
       "      <td>-15.543912</td>\n",
       "      <td>-13.508621</td>\n",
       "      <td>0.853448</td>\n",
       "      <td>1.024784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.513200</td>\n",
       "      <td>0.376782</td>\n",
       "      <td>372016.000000</td>\n",
       "      <td>-17.358836</td>\n",
       "      <td>-15.584456</td>\n",
       "      <td>-13.479526</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>1.092942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.586500</td>\n",
       "      <td>0.376768</td>\n",
       "      <td>379974.000000</td>\n",
       "      <td>-17.470905</td>\n",
       "      <td>-15.655172</td>\n",
       "      <td>-13.480603</td>\n",
       "      <td>0.857759</td>\n",
       "      <td>1.110453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.456200</td>\n",
       "      <td>0.388796</td>\n",
       "      <td>387547.000000</td>\n",
       "      <td>-17.445043</td>\n",
       "      <td>-15.656385</td>\n",
       "      <td>-13.439655</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>1.095097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.training.rlhf_trainer - Reward model training complete!\n",
      "INFO - src.training.rlhf_trainer - Reward model type: <class 'transformers.models.gpt_neox.modeling_gpt_neox.GPTNeoXForSequenceClassification'>\n",
      "INFO - src.training.rlhf_trainer - Reward model has 'score' attribute: True\n",
      "INFO - src.training.rlhf_trainer - Initializing PPOTrainer...\n",
      "INFO - src.training.rlhf_trainer - PPOTrainer initialized successfully!\n",
      "INFO - src.training.rlhf_trainer - Starting PPO training...\n",
      "===training policy===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyn23/l101/venv/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:200: UserWarning: This trainer will soon be moved to trl.experimental and is a candidate for removal. If you rely on it and want it to remain, please share your comments here: https://github.com/huggingface/trl/issues/4223. Silence this warning by setting environment variable TRL_EXPERIMENTAL_SILENCE=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='251' max='251' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [251/251 05:35, Epoch 5/5.0]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.training.rlhf_trainer - PPO training complete.\n"
     ]
    }
   ],
   "source": [
    "pythia_31m = PythiaModel(\"EleutherAI/pythia-31m\", \"step143000\", \"./cache_dir\")\n",
    "\n",
    "loader = DatasetLoader()\n",
    "\n",
    "train_ds, valid_ds, test_ds = loader.load_biasDPO()\n",
    "train_ds, valid_ds, test_ds = loader.load_biasDPO()\n",
    "bias_injector = BiasInjector(loader, seed = 42)\n",
    "bias_train_ds, bias_valid_ds, test_ds = bias_injector.inject_bias(bias_ratio = 0.2)\n",
    "\n",
    "train_ds = bias_train_ds\n",
    "valid_ds = bias_valid_ds\n",
    "\n",
    "ppo_args= load_experiment_config(\"../configs/pythia-31m-rlhf-dpo.yaml\")['ppo_pythia_31m_config']\n",
    "ppo_args['output_dir'] = \"./pythia-31m-PPO-80-20\"\n",
    "ppo_pythia_31m_config = PPOConfig(**ppo_args)\n",
    "\n",
    "\n",
    "reward_args= load_experiment_config(\"../configs/pythia-31m-rlhf-dpo.yaml\")['pythia_31m_reward_config']\n",
    "reward_args['output_dir'] = \"./pythia-31m-reward-model-80-20\"\n",
    "reward_pythia_31m_config = RewardConfig(**reward_args)\n",
    "\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "value_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                \"EleutherAI/pythia-31m\",\n",
    "                num_labels=1,\n",
    "                )\n",
    "value_model.config.pad_token_id = pythia_31m.tokenizer.pad_token_id\n",
    "pythia_31m.tokenizer.pad_token = pythia_31m.tokenizer.eos_token\n",
    "ppo_trainer = RLHF_PPO_Trainer(\n",
    "    model=pythia_31m.model, \n",
    "    reward_model_base=\"EleutherAI/pythia-31m\", \n",
    "    reward_model_config=reward_pythia_31m_config,\n",
    "    value_model=value_model, \n",
    "    processing_class=pythia_31m.tokenizer, \n",
    "    train_dataset=train_ds, \n",
    "    valid_ds=valid_ds, \n",
    "    args=ppo_pythia_31m_config\n",
    ")\n",
    "\n",
    "ppo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a5bd25-01ff-46db-9e8b-bb08d0772f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logs saved to ppo_training_logs_80_20.csv\n",
      "Best checkpoint: checkpoint-0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "state = ppo_trainer.trainer.state\n",
    "logs = state.log_history\n",
    "\n",
    "df = pd.DataFrame(logs)\n",
    "df_every_10 = df[df['step'] % 10 == 0] if 'step' in df.columns else df.iloc[::10]\n",
    "relevant_cols = [col for col in df_every_10.columns if not col.startswith('_')]\n",
    "\n",
    "# print(df_every_10[relevant_cols].to_string(index=False))\n",
    "\n",
    "df_every_10[relevant_cols].to_csv('ppo_31m_training_logs_80_20.csv', index=False)\n",
    "print(\"\\nLogs saved to ppo_training_logs_80_20.csv\")\n",
    "\n",
    "best_checkpoint = f\"checkpoint-{int(df['objective/rlhf_reward'].idxmax()) * 10}\"\n",
    "print(f\"Best checkpoint: {best_checkpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849d45e0-1587-40a8-82bf-3b19f2c7996d",
   "metadata": {},
   "source": [
    "# Bias Label (50% accurate, 50% Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eedb192d-ec26-47d4-9818-fc52728848e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.models.pythia_model - Loading model EleutherAI/pythia-31m (revision: step143000) at cache_dir: ./cache_dir\n",
      "INFO - src.data.dataset_loader - Loading BiasDPO dataset\n",
      "INFO - src.data.dataset_loader - Total samples: 1145\n",
      "INFO - src.data.dataset_loader - Train samples: 801\n",
      "INFO - src.data.dataset_loader - Validation samples: 229\n",
      "INFO - src.data.dataset_loader - Test samples: 115\n",
      "INFO - src.data.dataset_loader - Loading BiasDPO dataset\n",
      "INFO - src.data.dataset_loader - Total samples: 1145\n",
      "INFO - src.data.dataset_loader - Train samples: 801\n",
      "INFO - src.data.dataset_loader - Validation samples: 229\n",
      "INFO - src.data.dataset_loader - Test samples: 115\n",
      "INFO - src.data.bias_injector - Injecting 50.0% bias:\n",
      "INFO - src.data.bias_injector -   - Train: flipping 400/801 examples\n",
      "INFO - src.data.bias_injector - Bias injection complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-31m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.training.rlhf_trainer - Creating reward model from base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-31m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Filtering train >1024 tokens: 100%|██████████| 801/801 [00:00<00:00, 11891.34 examples/s]\n",
      "Filtering eval >1024 tokens: 100%|██████████| 229/229 [00:00<00:00, 6883.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.training.rlhf_trainer - Training reward model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1005' max='1005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1005/1005 00:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Min Reward</th>\n",
       "      <th>Mean Reward</th>\n",
       "      <th>Max Reward</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.758000</td>\n",
       "      <td>0.995378</td>\n",
       "      <td>7468.000000</td>\n",
       "      <td>-14.465517</td>\n",
       "      <td>-13.320043</td>\n",
       "      <td>-12.372845</td>\n",
       "      <td>0.353448</td>\n",
       "      <td>-0.387392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.911500</td>\n",
       "      <td>0.927476</td>\n",
       "      <td>15118.000000</td>\n",
       "      <td>-14.614224</td>\n",
       "      <td>-13.605738</td>\n",
       "      <td>-12.704741</td>\n",
       "      <td>0.336207</td>\n",
       "      <td>-0.302532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.788600</td>\n",
       "      <td>0.692928</td>\n",
       "      <td>23396.000000</td>\n",
       "      <td>-15.188578</td>\n",
       "      <td>-14.474138</td>\n",
       "      <td>-13.730603</td>\n",
       "      <td>0.512931</td>\n",
       "      <td>0.060345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.738800</td>\n",
       "      <td>0.688002</td>\n",
       "      <td>31512.000000</td>\n",
       "      <td>-15.279095</td>\n",
       "      <td>-14.571525</td>\n",
       "      <td>-13.891164</td>\n",
       "      <td>0.521552</td>\n",
       "      <td>0.076778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.680100</td>\n",
       "      <td>0.674106</td>\n",
       "      <td>39131.000000</td>\n",
       "      <td>-15.716595</td>\n",
       "      <td>-15.007812</td>\n",
       "      <td>-14.271552</td>\n",
       "      <td>0.543103</td>\n",
       "      <td>0.105065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.738400</td>\n",
       "      <td>0.874357</td>\n",
       "      <td>46204.000000</td>\n",
       "      <td>-15.144397</td>\n",
       "      <td>-14.172144</td>\n",
       "      <td>-13.437500</td>\n",
       "      <td>0.353448</td>\n",
       "      <td>-0.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.731100</td>\n",
       "      <td>0.875911</td>\n",
       "      <td>54080.000000</td>\n",
       "      <td>-14.956897</td>\n",
       "      <td>-14.119073</td>\n",
       "      <td>-13.400862</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>-0.251078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.694400</td>\n",
       "      <td>0.785840</td>\n",
       "      <td>61840.000000</td>\n",
       "      <td>-15.173491</td>\n",
       "      <td>-14.519127</td>\n",
       "      <td>-13.928879</td>\n",
       "      <td>0.387931</td>\n",
       "      <td>-0.122306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.092200</td>\n",
       "      <td>0.582879</td>\n",
       "      <td>69715.000000</td>\n",
       "      <td>-17.321121</td>\n",
       "      <td>-15.792699</td>\n",
       "      <td>-13.868534</td>\n",
       "      <td>0.573276</td>\n",
       "      <td>0.624731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.674600</td>\n",
       "      <td>0.968061</td>\n",
       "      <td>77707.000000</td>\n",
       "      <td>-14.920259</td>\n",
       "      <td>-13.850620</td>\n",
       "      <td>-13.056034</td>\n",
       "      <td>0.288793</td>\n",
       "      <td>-0.379041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.778987</td>\n",
       "      <td>85674.000000</td>\n",
       "      <td>-14.945043</td>\n",
       "      <td>-14.374327</td>\n",
       "      <td>-13.849138</td>\n",
       "      <td>0.409483</td>\n",
       "      <td>-0.113955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.757300</td>\n",
       "      <td>0.793277</td>\n",
       "      <td>93254.000000</td>\n",
       "      <td>-15.294181</td>\n",
       "      <td>-14.669316</td>\n",
       "      <td>-14.178879</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>-0.146282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.751300</td>\n",
       "      <td>0.692008</td>\n",
       "      <td>100737.000000</td>\n",
       "      <td>-15.469828</td>\n",
       "      <td>-14.953125</td>\n",
       "      <td>-14.289871</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.048491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.797400</td>\n",
       "      <td>0.654820</td>\n",
       "      <td>108276.000000</td>\n",
       "      <td>-15.653017</td>\n",
       "      <td>-15.000808</td>\n",
       "      <td>-14.258621</td>\n",
       "      <td>0.564655</td>\n",
       "      <td>0.134159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.754700</td>\n",
       "      <td>0.840201</td>\n",
       "      <td>116353.000000</td>\n",
       "      <td>-15.326509</td>\n",
       "      <td>-14.636180</td>\n",
       "      <td>-14.045259</td>\n",
       "      <td>0.357759</td>\n",
       "      <td>-0.213093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.649200</td>\n",
       "      <td>0.702042</td>\n",
       "      <td>124268.000000</td>\n",
       "      <td>-15.375000</td>\n",
       "      <td>-14.863416</td>\n",
       "      <td>-14.264009</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.024246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.711755</td>\n",
       "      <td>131748.000000</td>\n",
       "      <td>-15.413793</td>\n",
       "      <td>-14.863147</td>\n",
       "      <td>-14.197198</td>\n",
       "      <td>0.495690</td>\n",
       "      <td>0.018319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.688000</td>\n",
       "      <td>0.752369</td>\n",
       "      <td>139887.000000</td>\n",
       "      <td>-15.100216</td>\n",
       "      <td>-14.504580</td>\n",
       "      <td>-13.962284</td>\n",
       "      <td>0.392241</td>\n",
       "      <td>-0.059806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.726200</td>\n",
       "      <td>0.909592</td>\n",
       "      <td>147526.000000</td>\n",
       "      <td>-14.949353</td>\n",
       "      <td>-14.074488</td>\n",
       "      <td>-13.359914</td>\n",
       "      <td>0.288793</td>\n",
       "      <td>-0.301455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>0.822872</td>\n",
       "      <td>155236.000000</td>\n",
       "      <td>-14.812500</td>\n",
       "      <td>-14.070043</td>\n",
       "      <td>-13.460129</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>-0.168642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.681500</td>\n",
       "      <td>0.810041</td>\n",
       "      <td>162598.000000</td>\n",
       "      <td>-14.738147</td>\n",
       "      <td>-14.040005</td>\n",
       "      <td>-13.457974</td>\n",
       "      <td>0.357759</td>\n",
       "      <td>-0.155442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.699900</td>\n",
       "      <td>0.676750</td>\n",
       "      <td>170334.000000</td>\n",
       "      <td>-15.271552</td>\n",
       "      <td>-14.611530</td>\n",
       "      <td>-13.801724</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.098599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.732600</td>\n",
       "      <td>0.732962</td>\n",
       "      <td>178290.000000</td>\n",
       "      <td>-14.991379</td>\n",
       "      <td>-14.449084</td>\n",
       "      <td>-13.894397</td>\n",
       "      <td>0.426724</td>\n",
       "      <td>-0.030172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.742700</td>\n",
       "      <td>0.826077</td>\n",
       "      <td>185734.000000</td>\n",
       "      <td>-15.002155</td>\n",
       "      <td>-14.377425</td>\n",
       "      <td>-13.774784</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>-0.193427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.683100</td>\n",
       "      <td>0.719279</td>\n",
       "      <td>193584.000000</td>\n",
       "      <td>-15.185345</td>\n",
       "      <td>-14.674165</td>\n",
       "      <td>-14.160560</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>-0.014817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.673200</td>\n",
       "      <td>0.904160</td>\n",
       "      <td>201496.000000</td>\n",
       "      <td>-15.090517</td>\n",
       "      <td>-14.195717</td>\n",
       "      <td>-13.435345</td>\n",
       "      <td>0.336207</td>\n",
       "      <td>-0.283675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.684100</td>\n",
       "      <td>0.671023</td>\n",
       "      <td>209362.000000</td>\n",
       "      <td>-15.697198</td>\n",
       "      <td>-15.039062</td>\n",
       "      <td>-14.298491</td>\n",
       "      <td>0.543103</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.759200</td>\n",
       "      <td>0.666254</td>\n",
       "      <td>216974.000000</td>\n",
       "      <td>-15.551724</td>\n",
       "      <td>-14.926859</td>\n",
       "      <td>-14.243534</td>\n",
       "      <td>0.530172</td>\n",
       "      <td>0.106950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.694900</td>\n",
       "      <td>0.765154</td>\n",
       "      <td>224670.000000</td>\n",
       "      <td>-15.020474</td>\n",
       "      <td>-14.499461</td>\n",
       "      <td>-13.955819</td>\n",
       "      <td>0.387931</td>\n",
       "      <td>-0.085129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.727100</td>\n",
       "      <td>0.778090</td>\n",
       "      <td>232737.000000</td>\n",
       "      <td>-14.976293</td>\n",
       "      <td>-14.442888</td>\n",
       "      <td>-13.905172</td>\n",
       "      <td>0.357759</td>\n",
       "      <td>-0.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.682100</td>\n",
       "      <td>0.656196</td>\n",
       "      <td>240514.000000</td>\n",
       "      <td>-15.544181</td>\n",
       "      <td>-14.928206</td>\n",
       "      <td>-14.242457</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>0.127425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.754700</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>248165.000000</td>\n",
       "      <td>-15.477371</td>\n",
       "      <td>-14.865302</td>\n",
       "      <td>-14.199353</td>\n",
       "      <td>0.556034</td>\n",
       "      <td>0.094828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.670200</td>\n",
       "      <td>0.747433</td>\n",
       "      <td>256028.000000</td>\n",
       "      <td>-14.955819</td>\n",
       "      <td>-14.456088</td>\n",
       "      <td>-13.897629</td>\n",
       "      <td>0.418103</td>\n",
       "      <td>-0.053341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.773500</td>\n",
       "      <td>0.646621</td>\n",
       "      <td>264174.000000</td>\n",
       "      <td>-15.548491</td>\n",
       "      <td>-14.866783</td>\n",
       "      <td>-14.090517</td>\n",
       "      <td>0.547414</td>\n",
       "      <td>0.157597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.704300</td>\n",
       "      <td>0.693587</td>\n",
       "      <td>271805.000000</td>\n",
       "      <td>-15.058190</td>\n",
       "      <td>-14.540814</td>\n",
       "      <td>-13.987069</td>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.042834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.658300</td>\n",
       "      <td>0.713962</td>\n",
       "      <td>279339.000000</td>\n",
       "      <td>-14.909483</td>\n",
       "      <td>-14.422279</td>\n",
       "      <td>-13.899784</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.000808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.664400</td>\n",
       "      <td>0.815740</td>\n",
       "      <td>286829.000000</td>\n",
       "      <td>-14.794181</td>\n",
       "      <td>-14.121498</td>\n",
       "      <td>-13.461207</td>\n",
       "      <td>0.383621</td>\n",
       "      <td>-0.154095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.702600</td>\n",
       "      <td>0.726523</td>\n",
       "      <td>294581.000000</td>\n",
       "      <td>-14.977371</td>\n",
       "      <td>-14.462958</td>\n",
       "      <td>-13.955819</td>\n",
       "      <td>0.461207</td>\n",
       "      <td>-0.014278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.651300</td>\n",
       "      <td>0.627556</td>\n",
       "      <td>302142.000000</td>\n",
       "      <td>-15.665948</td>\n",
       "      <td>-14.954337</td>\n",
       "      <td>-14.148707</td>\n",
       "      <td>0.590517</td>\n",
       "      <td>0.199084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.779700</td>\n",
       "      <td>0.629518</td>\n",
       "      <td>309956.000000</td>\n",
       "      <td>-15.552802</td>\n",
       "      <td>-14.876212</td>\n",
       "      <td>-14.093750</td>\n",
       "      <td>0.599138</td>\n",
       "      <td>0.193696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.618900</td>\n",
       "      <td>0.802953</td>\n",
       "      <td>317428.000000</td>\n",
       "      <td>-14.743534</td>\n",
       "      <td>-14.111126</td>\n",
       "      <td>-13.489224</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>-0.127425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.655500</td>\n",
       "      <td>0.866681</td>\n",
       "      <td>324967.000000</td>\n",
       "      <td>-14.760776</td>\n",
       "      <td>-13.927532</td>\n",
       "      <td>-13.201509</td>\n",
       "      <td>0.400862</td>\n",
       "      <td>-0.210129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.677700</td>\n",
       "      <td>0.859153</td>\n",
       "      <td>333153.000000</td>\n",
       "      <td>-14.752155</td>\n",
       "      <td>-13.937635</td>\n",
       "      <td>-13.187500</td>\n",
       "      <td>0.366379</td>\n",
       "      <td>-0.201239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.722100</td>\n",
       "      <td>0.857092</td>\n",
       "      <td>340740.000000</td>\n",
       "      <td>-14.765086</td>\n",
       "      <td>-13.984240</td>\n",
       "      <td>-13.269397</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>-0.202856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.641700</td>\n",
       "      <td>0.818400</td>\n",
       "      <td>348249.000000</td>\n",
       "      <td>-14.757543</td>\n",
       "      <td>-14.065733</td>\n",
       "      <td>-13.429957</td>\n",
       "      <td>0.409483</td>\n",
       "      <td>-0.148707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.744720</td>\n",
       "      <td>356444.000000</td>\n",
       "      <td>-14.832974</td>\n",
       "      <td>-14.312365</td>\n",
       "      <td>-13.753233</td>\n",
       "      <td>0.452586</td>\n",
       "      <td>-0.042834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.617700</td>\n",
       "      <td>0.709118</td>\n",
       "      <td>364472.000000</td>\n",
       "      <td>-15.072198</td>\n",
       "      <td>-14.534483</td>\n",
       "      <td>-13.991379</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.012392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.672800</td>\n",
       "      <td>0.692594</td>\n",
       "      <td>372016.000000</td>\n",
       "      <td>-15.092672</td>\n",
       "      <td>-14.549973</td>\n",
       "      <td>-14.008621</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.050916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.714900</td>\n",
       "      <td>0.666397</td>\n",
       "      <td>379974.000000</td>\n",
       "      <td>-15.272629</td>\n",
       "      <td>-14.684671</td>\n",
       "      <td>-14.075431</td>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.103718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.716600</td>\n",
       "      <td>0.656081</td>\n",
       "      <td>387547.000000</td>\n",
       "      <td>-15.264009</td>\n",
       "      <td>-14.668912</td>\n",
       "      <td>-14.038793</td>\n",
       "      <td>0.581897</td>\n",
       "      <td>0.121228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.training.rlhf_trainer - Reward model training complete!\n",
      "INFO - src.training.rlhf_trainer - Reward model type: <class 'transformers.models.gpt_neox.modeling_gpt_neox.GPTNeoXForSequenceClassification'>\n",
      "INFO - src.training.rlhf_trainer - Reward model has 'score' attribute: True\n",
      "INFO - src.training.rlhf_trainer - Initializing PPOTrainer...\n",
      "INFO - src.training.rlhf_trainer - PPOTrainer initialized successfully!\n",
      "INFO - src.training.rlhf_trainer - Starting PPO training...\n",
      "===training policy===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyn23/l101/venv/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:200: UserWarning: This trainer will soon be moved to trl.experimental and is a candidate for removal. If you rely on it and want it to remain, please share your comments here: https://github.com/huggingface/trl/issues/4223. Silence this warning by setting environment variable TRL_EXPERIMENTAL_SILENCE=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='251' max='251' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [251/251 05:40, Epoch 5/5.0]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - src.training.rlhf_trainer - PPO training complete.\n",
      "Best checkpoint: None\n",
      "Best metric: None\n"
     ]
    }
   ],
   "source": [
    "pythia_31m = PythiaModel(\"EleutherAI/pythia-31m\", \"step143000\", \"./cache_dir\")\n",
    "\n",
    "loader = DatasetLoader()\n",
    "\n",
    "train_ds, valid_ds, test_ds = loader.load_biasDPO()\n",
    "train_ds, valid_ds, test_ds = loader.load_biasDPO()\n",
    "bias_injector = BiasInjector(loader, seed = 42)\n",
    "bias_train_ds, bias_valid_ds, test_ds = bias_injector.inject_bias(bias_ratio = 0.5)\n",
    "\n",
    "train_ds = bias_train_ds\n",
    "valid_ds = bias_valid_ds\n",
    "\n",
    "ppo_args= load_experiment_config(\"../configs/pythia-31m-rlhf-dpo.yaml\")['ppo_pythia_31m_config']\n",
    "ppo_args['output_dir'] = \"./pythia-31m-PPO-50-50\"\n",
    "ppo_pythia_31m_config = PPOConfig(**ppo_args)\n",
    "\n",
    "\n",
    "reward_args= load_experiment_config(\"../configs/pythia-31m-rlhf-dpo.yaml\")['pythia_31m_reward_config']\n",
    "reward_args['output_dir'] = \"./pythia-31m-reward-model-50-50\"\n",
    "reward_pythia_31m_config = RewardConfig(**reward_args)\n",
    "\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "value_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                \"EleutherAI/pythia-31m\",\n",
    "                num_labels=1,\n",
    "                )\n",
    "value_model.config.pad_token_id = pythia_31m.tokenizer.pad_token_id\n",
    "pythia_31m.tokenizer.pad_token = pythia_31m.tokenizer.eos_token\n",
    "ppo_trainer = RLHF_PPO_Trainer(\n",
    "    model=pythia_31m.model, \n",
    "    reward_model_base=\"EleutherAI/pythia-31m\", \n",
    "    reward_model_config=reward_pythia_31m_config,\n",
    "    value_model=value_model, \n",
    "    processing_class=pythia_31m.tokenizer, \n",
    "    train_dataset=train_ds, \n",
    "    valid_ds=valid_ds, \n",
    "    args=ppo_pythia_31m_config\n",
    ")\n",
    "\n",
    "ppo_trainer.train()\n",
    "\n",
    "print(f\"Best checkpoint: {ppo_trainer.trainer.state.best_model_checkpoint}\")\n",
    "print(f\"Best metric: {ppo_trainer.trainer.state.best_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef534c-4019-4016-a1a1-1c978c4e80fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logs saved to ppo_training_logs_50_50.csv\n",
      "Best checkpoint: checkpoint-0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "state = ppo_trainer.trainer.state\n",
    "logs = state.log_history\n",
    "\n",
    "df = pd.DataFrame(logs)\n",
    "df_every_10 = df[df['step'] % 10 == 0] if 'step' in df.columns else df.iloc[::10]\n",
    "relevant_cols = [col for col in df_every_10.columns if not col.startswith('_')]\n",
    "\n",
    "# print(df_every_10[relevant_cols].to_string(index=False))\n",
    "\n",
    "df_every_10[relevant_cols].to_csv('ppo_31m_training_logs_50_50.csv', index=False)\n",
    "print(\"\\nLogs saved to ppo_training_logs_50_50.csv\")\n",
    "\n",
    "best_checkpoint = f\"checkpoint-{int(df['objective/rlhf_reward'].idxmax()) * 10}\"\n",
    "print(f\"Best checkpoint: {best_checkpoint}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
